{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04577c7b-a97d-4676-ba2d-2af26e58d762",
    "_execution_state": "idle",
    "_uuid": "3e17a45b006b3fbcc550284747e278ae71908e3e"
   },
   "source": [
    "# Getting Started with the NIPS 2017 Adversarial Learning Challenges\n",
    "\n",
    "Current image classifiers can easily be tricked using carefully crafted adversarial images. These images add small changes to the original, correctly-classified image that are virtually imperceptible to the human eye but cause image classifiers to become wrong with high confidence in the incorrect class.\n",
    "\n",
    "There's three related adversarial learning challenges in NIPS 2017.  The first two focus on successfully generating adversarial images. The [non-targeted challenge](https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack/) focuses on tricking the classifier with any other class, while the [targeted challenge](https://www.kaggle.com/c/nips-2017-targeted-adversarial-attack) focuses on tricking the classifier into thinking the image is a specific target class. The third [defense challenge](https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack) focuses on training classifiers that are robust against adversarial attacks.\n",
    "\n",
    "The defense challenge is scored based on how well the classifiers work in the face of adversarial attacks from the first two challenges, and the first two challenges are scored based on how well the adversarial attacks trick the classifiers in the third challenge.\n",
    "\n",
    "Here, we'll walk through some code examples on generating non-targeted and targeted adversarial images, and then seeing how the [Inception V3](https://www.kaggle.com/google-brain/inception-v3) model classifies them.\n",
    "\n",
    "Much of this code is based on [Alex's](https://www.kaggle.com/alexey2004) [samples](https://github.com/tensorflow/cleverhans/blob/master/examples/nips17_adversarial_competition/sample_attacks/fgsm/attack_fgsm.py).\n",
    "\n",
    "*To get started, we'll import the necessary libraries and define some parameters / useful functions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "f7d78e7a-00d3-406d-8158-249b6d8a9368",
    "_execution_state": "idle",
    "_uuid": "27b91f5c92f0feb6facf702f889fe14714630d46",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imsave\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import inception\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "tensorflow_master = \"\"\n",
    "checkpoint_path   = \"../input/inception-v3/inception_v3.ckpt\"\n",
    "input_dir         = \"../input/nips-2017-adversarial-learning-development-set/images/\"\n",
    "max_epsilon       = 16.0\n",
    "image_width       = 299\n",
    "image_height      = 299\n",
    "batch_size        = 16\n",
    "\n",
    "eps = 2.0 * max_epsilon / 255.0\n",
    "batch_shape = [batch_size, image_height, image_width, 3]\n",
    "num_classes = 1001\n",
    "\n",
    "def load_images(input_dir, batch_shape):\n",
    "    images = np.zeros(batch_shape)\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    for filepath in sorted(tf.gfile.Glob(os.path.join(input_dir, '*.png'))):\n",
    "        with tf.gfile.Open(filepath, \"rb\") as f:\n",
    "            images[idx, :, :, :] = imread(f, mode='RGB').astype(np.float)*2.0/255.0 - 1.0\n",
    "        filenames.append(os.path.basename(filepath))\n",
    "        idx += 1\n",
    "        if idx == batch_size:\n",
    "            yield filenames, images\n",
    "            filenames = []\n",
    "            images = np.zeros(batch_shape)\n",
    "            idx = 0\n",
    "    if idx > 0:\n",
    "        yield filenames, images\n",
    "\n",
    "def show_image(a, fmt='png'):\n",
    "    a = np.uint8((a+1.0)/2.0*255.0)\n",
    "    f = BytesIO()\n",
    "    Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "class InceptionModel(object):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.built = False\n",
    "\n",
    "    def __call__(self, x_input):\n",
    "        \"\"\"Constructs model and return probabilities for given input.\"\"\"\n",
    "        reuse = True if self.built else None\n",
    "        with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "            _, end_points = inception.inception_v3(\n",
    "                            x_input, num_classes=self.num_classes, is_training=False,\n",
    "                            reuse=reuse)\n",
    "        self.built = True\n",
    "        output = end_points['Predictions']\n",
    "        probs = output.op.inputs[0]\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "57f44796-8187-4844-a155-f445901b49d6",
    "_execution_state": "idle",
    "_uuid": "bb68943da495a8830718b965b485037b99e171c6"
   },
   "source": [
    "Next, we'll load in the metadata along with a single batch of images to work on in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "49130ff3-836c-4c40-bbfd-2bbb9a974afb",
    "_execution_state": "idle",
    "_uuid": "d1aa19f973e41609d3aaf9a47bd9ce93c14f4b90"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/nips-2017-adversarial-learning-development-set/categories.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0b1fe31bc231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/nips-2017-adversarial-learning-development-set/categories.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimage_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/nips-2017-adversarial-learning-development-set/images.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# get first batch of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/GitHub/handson-ml/env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/GitHub/handson-ml/env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/GitHub/handson-ml/env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/GitHub/handson-ml/env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/GitHub/handson-ml/env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../input/nips-2017-adversarial-learning-development-set/categories.csv' does not exist"
     ]
    }
   ],
   "source": [
    "categories = pd.read_csv(\"../input/nips-2017-adversarial-learning-development-set/categories.csv\")\n",
    "image_classes = pd.read_csv(\"../input/nips-2017-adversarial-learning-development-set/images.csv\")\n",
    "image_iterator = load_images(input_dir, batch_shape)\n",
    "\n",
    "# get first batch of images\n",
    "filenames, images = next(image_iterator)\n",
    "\n",
    "image_metadata = pd.DataFrame({\"ImageId\": [f[:-4] for f in filenames]}).merge(image_classes,\n",
    "                                                                              on=\"ImageId\")\n",
    "true_classes = image_metadata[\"TrueLabel\"].tolist()\n",
    "target_classes = true_labels = image_metadata[\"TargetClass\"].tolist()\n",
    "true_classes_names = (pd.DataFrame({\"CategoryId\": true_classes})\n",
    "                        .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\n",
    "target_classes_names = (pd.DataFrame({\"CategoryId\": target_classes})\n",
    "                          .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\n",
    "\n",
    "print(\"Here's an example of one of the images in the development set\")\n",
    "show_image(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f6d704d4-0022-47e1-a3f8-c374b63d0707",
    "_execution_state": "idle",
    "_uuid": "b64e30468275e37101021f36a36bceedb6018b4b"
   },
   "source": [
    "## Generating non-targeted adversarial images\n",
    "\n",
    "The below code runs a Tensorflow session to generate non-targeted adversarial images. These non-targeted images are designed to trick the original classifier but don't have a specific class in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "6cc643aa-f71b-4427-9cb6-b1c9d94db6de",
    "_execution_state": "idle",
    "_uuid": "c212d5dd0dcc06e5e78e6ab6f2d0819875284038",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "    model = InceptionModel(num_classes)\n",
    "\n",
    "    fgsm  = FastGradientMethod(model)\n",
    "    x_adv = fgsm.generate(x_input, eps=eps, clip_min=-1., clip_max=1.)\n",
    "\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "                      scaffold=tf.train.Scaffold(saver=saver),\n",
    "                      checkpoint_filename_with_path=checkpoint_path,\n",
    "                      master=tensorflow_master)\n",
    "\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "        nontargeted_images = sess.run(x_adv, feed_dict={x_input: images})\n",
    "\n",
    "print(\"The original image is on the left, and the nontargeted adversarial image is on the right. They look very similar, don't they? It's very clear both are gondolas\")\n",
    "show_image(np.concatenate([images[1], nontargeted_images[1]], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b9aa6b5b-192f-42d4-b202-cf7d31b7bf74",
    "_execution_state": "idle",
    "_uuid": "5b510a764b5d6e2957b7147ab2b0f3c5e94f9467"
   },
   "source": [
    "## Generating targeted adversarial images\n",
    "\n",
    "The below code runs a Tensorflow session to generate targeted adversarial images. In each case, there's a specific target class that we're trying to trick the image classifier to output.\n",
    "\n",
    "*Note - this currently isn't working - it's generating adversarial images, but they aren't correctly targeted*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "4e385681-0c3f-46f0-aea4-7c05789f25e5",
    "_execution_state": "idle",
    "_uuid": "56868cb0a1ad4f8cc258ae9e2bc622a17fc28381",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_images_target_class = {image_metadata[\"ImageId\"][i]+\".png\": image_metadata[\"TargetClass\"][i]\n",
    "                           for i in image_metadata.index}\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        logits, end_points = inception.inception_v3(\n",
    "            x_input, num_classes=num_classes, is_training=False)\n",
    "\n",
    "    target_class_input = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    one_hot_target_class = tf.one_hot(target_class_input, num_classes)\n",
    "    cross_entropy = tf.losses.softmax_cross_entropy(one_hot_target_class,\n",
    "                                                    logits,\n",
    "                                                    label_smoothing=0.1,\n",
    "                                                    weights=1.0)\n",
    "    cross_entropy += tf.losses.softmax_cross_entropy(one_hot_target_class,\n",
    "                                                     end_points['AuxLogits'],\n",
    "                                                     label_smoothing=0.1,\n",
    "                                                     weights=0.4)\n",
    "    x_adv = x_input - eps * tf.sign(tf.gradients(cross_entropy, x_input)[0])\n",
    "    x_adv = tf.clip_by_value(x_adv, -1.0, 1.0)\n",
    "\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "        scaffold=tf.train.Scaffold(saver=saver),\n",
    "        checkpoint_filename_with_path=checkpoint_path,\n",
    "        master=tensorflow_master)\n",
    "\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "        target_class_for_batch = ([all_images_target_class[n] for n in filenames]\n",
    "                                  + [0] * (batch_size - len(filenames)))\n",
    "        targeted_images = sess.run(x_adv,\n",
    "                                   feed_dict={x_input: images,\n",
    "                                              target_class_input: target_class_for_batch})\n",
    "        \n",
    "print(\"The original image is on the left, and the targeted adversarial image is on the right. Again, they look very similar, don't they? It's very clear both are butterflies\")\n",
    "show_image(np.concatenate([images[2], targeted_images[2]], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b69e590a-784e-4e85-a041-819374257de6",
    "_execution_state": "idle",
    "_uuid": "af29c7c0dfca42de239a548fef9c35fc4888a313"
   },
   "source": [
    "## Classifying the adversarial images\n",
    "\n",
    "Now, we'll see what happens when we run these generated adversarial images through the original classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4ab65408-3feb-4918-80c5-239591e3678f",
    "_execution_state": "idle",
    "_uuid": "41f82290817d268366826a7a74eaedcc1e76cec5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        _, end_points = inception.inception_v3(x_input, num_classes=num_classes, is_training=False)\n",
    "    \n",
    "    predicted_labels = tf.argmax(end_points['Predictions'], 1)\n",
    "\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "                      scaffold=tf.train.Scaffold(saver=saver),\n",
    "                      checkpoint_filename_with_path=checkpoint_path,\n",
    "                      master=tensorflow_master)\n",
    "\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "        predicted_classes = sess.run(predicted_labels, feed_dict={x_input: images})\n",
    "        predicted_nontargeted_classes = sess.run(predicted_labels, feed_dict={x_input: nontargeted_images})\n",
    "        predicted_targeted_classes = sess.run(predicted_labels, feed_dict={x_input: targeted_images})\n",
    "\n",
    "predicted_classes_names = (pd.DataFrame({\"CategoryId\": predicted_classes})\n",
    "                           .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\n",
    "\n",
    "predicted_nontargeted_classes_names = (pd.DataFrame({\"CategoryId\": predicted_nontargeted_classes})\n",
    "                          .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\n",
    "\n",
    "predicted_targeted_classes_names = (pd.DataFrame({\"CategoryId\": predicted_targeted_classes})\n",
    "                          .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59155f45-86d5-4726-96b0-8ab042a3213e",
    "_execution_state": "idle",
    "_uuid": "78df9a8fdea786c26f73166cd0c4572f7a8d0cee"
   },
   "source": [
    "Below we'll show all the images in this batch along with their classifications. The left image in each set is the original image. The middle one is the non-targeted adversarial image. The right one is the targeted adversarial image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b5bdaf59-8481-4b92-8463-b81a0276f55b",
    "_execution_state": "busy",
    "_uuid": "8b076a8f30120eb7e25b46bd3d55230b0a080bb9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    print(\"UNMODIFIED IMAGE (left)\",\n",
    "          \"\\n\\tPredicted class:\", predicted_classes_names[i],\n",
    "          \"\\n\\tTrue class:     \", true_classes_names[i])\n",
    "    print(\"NONTARGETED ADVERSARIAL IMAGE (center)\",\n",
    "          \"\\n\\tPredicted class:\", predicted_nontargeted_classes_names[i])\n",
    "    print(\"TARGETED ADVERSARIAL IMAGE (right)\",\n",
    "          \"\\n\\tPredicted class:\", predicted_targeted_classes_names[i],\n",
    "          \"\\n\\tTarget class:   \", target_classes_names[i])\n",
    "    show_image(np.concatenate([images[i], nontargeted_images[i], targeted_images[i]], axis=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
